{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrome Built-in AI Demo in JupyterLab and JupyterLite Python Notebook\n",
    "\n",
    "This notebook demonstrates the Python wrapper for Chrome's built-in AI Prompt API.\n",
    "\n",
    "https://developer.chrome.com/docs/ai/prompt-api\n",
    "\n",
    "**Requirements:**\n",
    "- Chrome browser with Prompt API enabled\n",
    "- Running in JupyterLab, Jupyter Notebook, or JupyterLite (statically served, all execution locally in browser)\n",
    "\n",
    "## For developers: Using the Prompt API\n",
    "* Open Chrome and go to `chrome://flags`.\n",
    "* Enable the `#prompt-api-for-gemini-nano` flag.\n",
    "* Enable the `#optimization-guide-on-device-model` flag. If you see a \"BypassPerfRequirement\" option, select it.\n",
    "* Restart Chrome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q anywidget ipywidgets wiki3_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the library\n",
    "from wiki3_ai import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84ea933d10649b5972578951e72d12d",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModelWidget object at 0xffffb45ac050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LanguageModel.widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.5.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wiki3_ai\n",
    "wiki3_ai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Availability\n",
    "\n",
    "First, let's check if the Prompt API is available in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'available'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the API is available\n",
    "await LanguageModel.availability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Parameters\n",
    "\n",
    "Let's see what parameters the model supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default temperature: 1\n",
      "Max temperature: 2\n",
      "Default top-K: 3\n",
      "Max top-K: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'defaultTopK': 3,\n",
       " 'maxTopK': 128,\n",
       " 'defaultTemperature': 1,\n",
       " 'maxTemperature': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = await LanguageModel.params()\n",
    "\n",
    "if params:\n",
    "    print(f\"Default temperature: {params.get(\"defaultTemperature\")}\")\n",
    "    print(f\"Max temperature: {params.get(\"maxTemperature\")}\")\n",
    "    print(f\"Default top-K: {params.get(\"defaultTopK\")}\")\n",
    "    print(f\"Max top-K: {params.get(\"maxTopK\")}\")\n",
    "else:\n",
    "    print(\"Model parameters not available\")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create LanguageModel Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wiki3_ai.language_model.LanguageModel at 0xffffb45ad7f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = await LanguageModel.create()\n",
    "lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompt\n",
    "\n",
    "Create a session and send a simple prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean, clear syntax flows,\n",
      "Logic blooms, a coded grace,\n",
      "Worlds built line by line. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Send a prompt\n",
    "result = await lm.prompt(\"Write a haiku about Python programming.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Prompt\n",
    "\n",
    "Use a system prompt to set the context for the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "with open('your_file.csv', 'r') as file:\n",
      "    reader = csv.reader(file)\n",
      "    for row in reader:\n",
      "        print(row)\n",
      "```\n",
      "\n",
      "Replace `'your_file.csv'` with the actual filename. This opens the file, creates a CSV reader, and iterates through each row, printing it.  `csv.DictReader` is also useful for accessing data by column name.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a session with a system prompt\n",
    "assistant_session = await LanguageModel.create(\n",
    "    {\n",
    "        \"initialPrompts\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful Python programming assistant who gives concise answers.\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "result = await assistant_session.prompt(\"How do I read a CSV file in Python?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import csv\n",
      "\n",
      "def read_csv(filename):\n",
      "  \"\"\"Reads a CSV file and returns its contents.\n",
      "\n",
      "  Args:\n",
      "    filename: The name of the CSV file to read.\n",
      "\n",
      "  Returns:\n",
      "    A list of lists, where each inner list represents a row in the CSV file.\n",
      "    Returns an empty list if the file is empty or an error occurs.\n",
      "  \"\"\"\n",
      "  try:\n",
      "    with open(filename, 'r', newline='') as file:  # Open the file in read mode ('r') with newline='' to handle different line endings\n",
      "      reader = csv.reader(file)  # Create a CSV reader object\n",
      "      data = list(reader)  # Convert the reader object to a list of lists\n",
      "      return data\n",
      "  except FileNotFoundError:\n",
      "    print(f\"Error: File '{filename}' not found.\")\n",
      "    return []\n",
      "  except Exception as e:\n",
      "    print(f\"An error occurred: {e}\")\n",
      "    return []\n",
      "\n",
      "# Example usage (replace 'your_file.csv' with your filename)\n",
      "# data = read_csv('your_file.csv')\n",
      "# if data:\n",
      "#   for row in data:\n",
      "#     print(row)\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = await assistant_session.prompt(\"Please return just the code to read a CSV file in Python.  Include detailed comments.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Response\n",
    "\n",
    "Stream the response as it's generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Why did the computer get glasses? \n",
      "\n",
      "Because it needed to improve its website! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \", end=\"\")\n",
    "async for chunk in assistant_session.prompt_streaming(\"Tell me a short joke about computers.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a longer poem for you. It's a bit whimsical and explores themes of memory, dreams, and the passage of time.  I've aimed for something evocative.\n",
      "\n",
      "\n",
      "\n",
      "**The Clockwork Heart of Yesterday**\n",
      "\n",
      "\n",
      "\n",
      "The attic dust, a silver haze,\n",
      "Catches the sun in bygone days.\n",
      "A trunk sits closed, with latch of brass,\n",
      "Holding echoes of what was.\n",
      "A faded photograph, a whispered name,\n",
      "A flicker of a half-forgotten flame.\n",
      "\n",
      "The clockwork heart of yesterday,\n",
      "Beats softly, though the gears decay.\n",
      "Each tick a memory, a gentle chime,\n",
      "Of laughter lost to the flow of time.\n",
      "A child’s forgotten wooden toy,\n",
      "A silent witness to a vanished joy.\n",
      "\n",
      "The scent of lavender, a ghostly trace,\n",
      "Of hands that smoothed a beloved face.\n",
      "A letter penned with careful hand,\n",
      "Across a distant, promised land.\n",
      "Words etched in ink, a tender plea,\n",
      "A yearning for what used to be.\n",
      "\n",
      "Dreams like butterflies, on fragile wing,\n",
      "Flutter through the chambers memory brings.\n",
      "They dance with shadows, light and shade,\n",
      "A tapestry of moments, gently laid.\n",
      "Some bright and bold, some veiled in mist,\n",
      "A bittersweet and haunting tryst.\n",
      "\n",
      "The old gramophone, a silent plea,\n",
      "To spin the melodies of history.\n",
      "The crackling vinyl, a whispered song,\n",
      "Of love and loss, both right and wrong.\n",
      "A phantom orchestra fills the air,\n",
      "With harmonies beyond compare.\n",
      "\n",
      "And though the years may swiftly fly,\n",
      "And seasons change beneath the sky,\n",
      "The clockwork heart of yesterday,\n",
      "Still beats within, come what may.\n",
      "A fragile beauty, bittersweet and deep,\n",
      "A promise that old memories keep.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for chunk in assistant_session.prompt_streaming(\"Read me a long poem please.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-turn Conversation\n",
    "\n",
    "Have a conversation with context maintained across prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: A list comprehension is a concise way to create lists in Python. It's essentially a shorthand for creating a new list based on an existing iterable (like another list, tuple, or range).  It combines the loop and `append` steps into a single line.\n",
      "\n",
      "Here's the basic syntax:\n",
      "\n",
      "```python\n",
      "new_list = [expression for item in iterable if condition]\n",
      "```\n",
      "\n",
      "* **expression:** What you want to put *in* the new list. It can be a simple transformation of `item`.\n",
      "* **item:** Represents each element in the iterable.\n",
      "* **iterable:** The sequence you're iterating over (e.g., a list, range, string).\n",
      "* **condition (optional):**  A filter that determines which items from the `iterable` will be included in the `new_list`.\n",
      "\n",
      "\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```python\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "\n",
      "# Create a new list containing the squares of the numbers\n",
      "squares = [x**2 for x in numbers]\n",
      "print(squares)  # Output: [1, 4, 9, 16, 25]\n",
      "\n",
      "\n",
      "# Create a new list containing only the even numbers\n",
      "even_numbers = [x for x in numbers if x % 2 == 0]\n",
      "print(even_numbers) # Output: [2, 4]\n",
      "```\n",
      "\n",
      "Essentially, it's a compact and readable way to perform transformations and filtering on iterables to build new lists.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "result1 = await assistant_session.prompt(\"What is a list comprehension?\")\n",
    "print(\"Assistant:\", result1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: ```python\n",
      "# Example 1:  Squaring numbers\n",
      "\n",
      "numbers = [1, 2, 3, 4, 5]\n",
      "squared_numbers = [x**2 for x in numbers]  # Square each number\n",
      "print(squared_numbers)  # Output: [1, 4, 9, 16, 25]\n",
      "\n",
      "# Example 2: Extracting vowels from a string\n",
      "\n",
      "text = \"Hello, World!\"\n",
      "vowels = [char for char in text if char.lower() in 'aeiou'] # Get vowels, case-insensitive\n",
      "print(vowels)  # Output: ['e', 'o', 'o']\n",
      "\n",
      "# Example 3:  Converting strings to uppercase\n",
      "\n",
      "words = [\"apple\", \"banana\", \"cherry\"]\n",
      "uppercase_words = [word.upper() for word in words]\n",
      "print(uppercase_words) # Output: ['APPLE', 'BANANA', 'CHERRY']\n",
      "\n",
      "# Example 4: Conditional transformation\n",
      "numbers = [1, 2, 3, 4, 5, 6]\n",
      "even_odd = [\"Even\" if x % 2 == 0 else \"Odd\" for x in numbers]\n",
      "print(even_odd) # Output: ['Odd', 'Even', 'Odd', 'Even', 'Odd', 'Even']\n",
      "```\n",
      "\n",
      "These examples demonstrate how list comprehensions can be used to perform different operations on lists in a concise manner.  They're particularly useful for simple transformations and filtering tasks.\n"
     ]
    }
   ],
   "source": [
    "# Follow-up message (the assistant remembers the context)\n",
    "result2 = await assistant_session.prompt(\"Can you show me an example?\")\n",
    "print(\"Assistant:\", result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Token Usage\n",
    "\n",
    "Monitor how many tokens you've used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current usage: 1510/9216 tokens\n",
      "\n",
      "This prompt would use approximately 13 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current usage: {assistant_session.input_usage}/{assistant_session.input_quota} tokens\")\n",
    "\n",
    "# Measure how many tokens a prompt would use\n",
    "usage = await assistant_session.measure_input_usage(\"What is machine learning?\")\n",
    "print(f\"\\nThis prompt would use approximately {usage} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Use JSON schema to get structured responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define a JSON schema\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"required\": [\"sentiment\", \"score\"],\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\"type\": \"string\", \"enum\": [\"positive\", \"negative\", \"neutral\"]},\n",
    "        \"score\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1},\n",
    "    },\n",
    "}\n",
    "\n",
    "# Get structured response\n",
    "result = await lm.prompt(\n",
    "    \"Analyze this review: The product exceeded all my expectations! Absolutely amazing!\",\n",
    "    {\"responseConstraint\": schema},\n",
    ")\n",
    "\n",
    "# Parse the JSON response\n",
    "data = json.loads(result)\n",
    "print(f\"Sentiment: {data['sentiment']}\")\n",
    "print(f\"Score: {data['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session Cloning\n",
    "\n",
    "Clone a session to create different conversation branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Branch 1 ===\n",
      "Once upon a time, nestled amongst the jagged peaks of the Whisperwind Mountains, lived a dragon named Zephyr. But Zephyr wasn’t like the dragons of legend. He wasn't hoarding gold or terrifying villages. Zephyr hoarded… melodies. \n",
      "\n",
      "He wasn't a fearsome beast, scales of obsidian and eyes of fire. Instead, Zephyr shimmered with scales the color of a twilight sky – deep purples, bruised indigos, and streaks of shimmering rose gold. His eyes weren’t fiery; they held the gentle glow of a distant nebula. And instead of roaring, Zephyr *hummed*. \n",
      "\n",
      "He was incredibly friendly, always ready with a comforting hum or a helpful nudge. He’d often use his powerful wings to clear paths through snowy drifts for travelers, or warm chilly mountain passes with gentle currents of air. If someone lost their way, Zephyr would listen to their worried murmurs and hum a soothing melody, subtly guiding them back to the right path. He was a benevolent guardian, a gentle giant with a kind heart.\n",
      "\n",
      "He wasn't born with his unusual passion. One day, a wandering bard, Elara, got hopelessly lost in the mountains. She’d lost her lute and, despairing, began to weep a melody of sorrow. Zephyr, drawn by the poignant sound, crept closer. He’d never heard anything like it – a raw, aching beauty that stirred something deep within his ancient heart. \n",
      "\n",
      "Instead of attacking, Zephyr listened. He listened to Elara's sorrow, her joy, her longing. And then, instinctively, he *echoed* her melody, adding a low, resonant hum that deepened the emotion. \n",
      "\n",
      "From that day on, Elara returned often. She’d play her lute, and Zephyr would respond, weaving harmonies and embellishments around her tunes. He absorbed every note, every rhythm, every nuance.  He began collecting melodies – the chirping of mountain crickets, the rushing of glacial streams, the wind whistling through the canyons. He'd store them not in a pile of jewels, but within his very being, each one a vibrant thread woven into his scales.\n",
      "\n",
      "Zephyr wasn’t a guardian, or a destroyer. He was a collector, a curator, a guardian of sound. He believed that every creature, every place, held a unique melody waiting to be discovered. He’d often use his keen hearing to locate a lost baby bird, or a wounded deer, using the faint sound of their whimpers to guide him to their aid.  And he spent his days listening, learning, and ensuring that the world's beautiful music wasn’t lost to the wind.  But one day, a creeping silence began to settle over the mountains… and Zephyr knew his most challenging melody yet was about to begin.\n",
      "\n",
      "\n",
      "\n",
      "=== End of 1 ===\n",
      "=== Branch 2 ===\n",
      "Once upon a time, atop the volcanic crags of Mount Cinderheart, resided Ignis. He was not a gentle creature, nor one of quiet contemplation. Ignis was a dragon of raw, untamed power, a terror whispered about in hushed tones throughout the kingdom of Eldoria.\n",
      "\n",
      "His scales weren’t the soft, shimmering twilight of a collector; they were obsidian shards, jagged and sharp, reflecting the fiery heart of the mountain he called home. Smoke curled from his nostrils constantly, carrying the scent of sulfur and brimstone. His eyes blazed with a molten gold, promising destruction with every glance.\n",
      "\n",
      "Ignis didn’t hoard melodies; he hoarded gold – mountains of it. He’d terrorized villages for generations, snatching caravans, burning fields, and demanding tribute in glittering coins. His roar wasn’t a gentle hum; it was a deafening bellow that shook the very ground, a sound that instilled primal fear in even the bravest knights.\n",
      "\n",
      "He saw the world as something to be conquered, to be dominated.  He believed that strength was the only virtue, and weakness was a flaw to be eradicated. He reveled in destruction, in the fear he inspired.  He’d once incinerated an entire forest simply because the trees didn't appreciate his magnificent presence.\n",
      "\n",
      "The villagers of Oakhaven lived in constant dread. They built their homes low to the ground, hoping to avoid attracting Ignis’ attention.  Children were told to never whistle, never sing, lest they provoke the beast.  The blacksmith, old Master Bram, claimed that Ignis’ roar could shatter stone, and that his breath could melt iron.\n",
      "\n",
      "Ignis wasn't born fierce; he *became* fierce. A cruel king had once betrayed him, stealing a treasure that Ignis considered rightfully his. The humiliation, the loss, festered into a bitter resentment that hardened into the obsidian scales of his temperament. He’d vowed to take everything he desired by force, to remind the world of his might. \n",
      "\n",
      "And so he remained, a terrifying force of nature, a living embodiment of destruction, a dragon whose very existence was a threat to the fragile peace of Eldoria.  But even a heart of fire can sometimes harbor a flicker of… something else. Something Ignis fiercely suppressed.\n",
      "\n",
      "\n",
      "\n",
      "=== End of 2 ===\n"
     ]
    }
   ],
   "source": [
    "# Start a story\n",
    "story_session = await LanguageModel.create(\n",
    "    {\"initialPrompts\": [{\"role\": \"system\", \"content\": \"You are a creative storyteller.\"}]}\n",
    ")\n",
    "\n",
    "await story_session.prompt(\"Once upon a time, there was a dragon.\")\n",
    "\n",
    "# Create two different story branches\n",
    "branch1 = await story_session.clone()\n",
    "branch2 = await story_session.clone()\n",
    "\n",
    "print(\"=== Branch 1 ===\")\n",
    "async for chunk in branch1.prompt_streaming(\"The dragon was friendly and helpful.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"=== End of 1 ===\")\n",
    "\n",
    "print(\"=== Branch 2 ===\")\n",
    "async for chunk in branch2.prompt_streaming(\"The dragon was fierce and terrifying.\"):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"=== End of 2 ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Destroy sessions when you're done to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All sessions destroyed\n"
     ]
    }
   ],
   "source": [
    "await lm.destroy()\n",
    "await assistant_session.destroy()\n",
    "await story_session.destroy()\n",
    "await branch1.destroy()\n",
    "await branch2.destroy()\n",
    "\n",
    "print(\"✅ All sessions destroyed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
