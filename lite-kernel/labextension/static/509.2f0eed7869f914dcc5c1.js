"use strict";(self.webpackChunk_wiki3ai_lite_kernel=self.webpackChunk_wiki3ai_lite_kernel||[]).push([[509],{78:(e,t,n)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.ChatHttpKernel=void 0;const o=n(394),s=n(206);t.ChatHttpKernel=class{constructor(e={}){const t="undefined"!=typeof window?window.webllmModelId:void 0;this.modelName=e.model??t??"Llama-3.2-3B-Instruct-q4f16_1-MLC",this.model=(0,s.webLLM)(this.modelName,{initProgressCallback:e=>{"undefined"!=typeof window&&window.dispatchEvent(new CustomEvent("webllm:model-progress",{detail:e}))}}),console.log("[ChatHttpKernel] Using WebLLM model:",this.modelName)}async send(e){const t=await this.model.availability();if("unavailable"===t)throw new Error("Browser does not support WebLLM / WebGPU.");"downloadable"!==t&&"downloading"!==t||await this.model.createSessionWithProgress(e=>{"undefined"!=typeof window&&window.dispatchEvent(new CustomEvent("webllm:model-progress",{detail:e}))});const n=await(0,o.streamText)({model:this.model,messages:[{role:"user",content:e}]});let s="";for await(const e of n.textStream)s+=e;return s}}},79:(e,t,n)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.DEFAULT_WEBLLM_MODEL=t.WEBLLM_MODELS=void 0,t.isValidWebLLMModel=function(e){return t.WEBLLM_MODELS.includes(e)};const o=n(139);t.WEBLLM_MODELS=o.prebuiltAppConfig.model_list.map(e=>e.model_id),t.DEFAULT_WEBLLM_MODEL=["Llama-3.2-3B-Instruct-q4f16_1-MLC","Llama-3.1-8B-Instruct-q4f32_1-MLC","Mistral-7B-Instruct-v0.3-q4f16_1-MLC"].find(e=>t.WEBLLM_MODELS.includes(e))??t.WEBLLM_MODELS[0]},509:(e,t,n)=>{Object.defineProperty(t,"__esModule",{value:!0});const o=n(716),s=n(79),a="http-chat",l=[{id:"http-chat-kernel:plugin",autoStart:!0,activate:e=>{console.log("[http-chat-kernel] Activating plugin");const t=e.serviceManager?.kernelspecs;if(!t||"function"!=typeof t.register)return void console.warn("[http-chat-kernel] kernelspecs.register is not available; kernel will not be registered.",t);if(t.register({id:a,spec:{name:a,display_name:"HTTP Chat (ACP)",language:"python",argv:[],resources:{}},create:e=>(console.log("[http-chat-kernel] Creating HttpLiteKernel instance",e),new o.HttpLiteKernel(e))}),console.log(`[http-chat-kernel] Kernel spec '${a}' registered`),"undefined"==typeof document)return;const n=document.createElement("div");n.style.position="fixed",n.style.top="8px",n.style.right="8px",n.style.zIndex="9999",n.style.padding="4px 8px",n.style.background="rgba(0,0,0,0.7)",n.style.color="#fff",n.style.fontSize="12px",n.style.borderRadius="4px",n.style.display="flex",n.style.gap="4px",n.style.alignItems="center";const l=document.createElement("span");l.textContent="WebLLM model:",n.appendChild(l);const r=document.createElement("select"),i=window.localStorage.getItem("webllm:modelId")??s.DEFAULT_WEBLLM_MODEL;s.WEBLLM_MODELS.forEach(e=>{const t=document.createElement("option");t.value=e,t.textContent=e,e===i&&(t.selected=!0),r.appendChild(t)}),window.webllmModelId=i,r.onchange=()=>{window.webllmModelId=r.value,window.localStorage.setItem("webllm:modelId",r.value)},n.appendChild(r);const c=document.createElement("progress");c.max=1,c.value=0,c.style.width="120px",c.style.display="none",n.appendChild(c);const d=document.createElement("span");d.textContent="",n.appendChild(d),window.addEventListener("webllm:model-progress",e=>{const{detail:t={}}=e,{progress:n,text:o}=t,s=void 0!==n&&n>0&&n<1;c.style.display=s?"inline-block":"none",c.value=n??0,d.textContent=o??""}),document.body.appendChild(n)}}];t.default=l},716:(e,t,n)=>{Object.defineProperty(t,"__esModule",{value:!0}),t.HttpLiteKernel=void 0,t.createHttpLiteKernel=function(e){return new a(e)};const o=n(231),s=n(78);class a extends o.BaseKernel{constructor(e){super(e);const t=e.model;this.chat=new s.ChatHttpKernel({model:t})}async executeRequest(e){const t=String(e.code??"");try{const e=await this.chat.send(t);return this.publishExecuteResult({data:{"text/plain":e},metadata:{},execution_count:this.executionCount},this.parentHeader),{status:"ok",execution_count:this.executionCount,payload:[],user_expressions:{}}}catch(e){const t=e?.message??String(e);return this.publishExecuteError({ename:"Error",evalue:t,traceback:[]},this.parentHeader),{status:"error",execution_count:this.executionCount,ename:"Error",evalue:t,traceback:[]}}}async kernelInfoRequest(){return{status:"ok",protocol_version:"5.3",implementation:"http-lite-kernel",implementation_version:"0.1.0",language_info:{name:"markdown",version:"0.0.0",mimetype:"text/markdown",file_extension:".md"},banner:"HTTP-backed LLM chat kernel",help_links:[]}}async completeRequest(e){return{status:"ok",matches:[],cursor_start:e.cursor_pos??0,cursor_end:e.cursor_pos??0,metadata:{}}}async inspectRequest(e){return{status:"ok",found:!1,data:{},metadata:{}}}async isCompleteRequest(e){return{status:"complete",indent:""}}async commInfoRequest(e){return{status:"ok",comms:{}}}async historyRequest(e){return{status:"ok",history:[]}}async shutdownRequest(e){return{status:"ok",restart:!1}}async inputReply(e){}async commOpen(e){}async commMsg(e){}async commClose(e){}}t.HttpLiteKernel=a}}]);