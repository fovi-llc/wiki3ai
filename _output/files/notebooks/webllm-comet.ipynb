{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d37b1bfd-91ca-4ef8-bf63-83438cce2007",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Message listener attached!\n",
            "Initializing WebLLM engine...\n"
          ]
        }
      ],
      "source": [
        "# Create WebWorker with WebLLM\n",
        "worker_code = \"\"\"\n",
        "import * as webllm from 'https://esm.run/@mlc-ai/web-llm';\n",
        "\n",
        "let engine = null;\n",
        "\n",
        "self.onmessage = async function(e) {\n",
        "    const { type, data, id } = e.data;\n",
        "    \n",
        "    if (type === 'init') {\n",
        "        engine = await webllm.CreateMLCEngine(data.model, {\n",
        "            initProgressCallback: (progress) => {\n",
        "                self.postMessage({type: 'progress', data: progress, id});\n",
        "            }\n",
        "        });\n",
        "        self.postMessage({type: 'ready', id});\n",
        "    } else if (type === 'chat') {\n",
        "        const response = await engine.chat.completions.create({\n",
        "            messages: data.messages,\n",
        "            stream: false\n",
        "        });\n",
        "        self.postMessage({\n",
        "            type: 'response', \n",
        "            data: response.choices[0].message.content, \n",
        "            id\n",
        "        });\n",
        "    }\n",
        "};\n",
        "\"\"\"\n",
        "\n",
        "from js import Blob, URL, Worker\n",
        "blob = Blob.new([worker_code], {\"type\": \"application/javascript\"})\n",
        "worker_url = URL.createObjectURL(blob)\n",
        "worker = Worker.new(worker_url)\n",
        "\n",
        "import js\n",
        "import asyncio\n",
        "\n",
        "from js import console\n",
        "import asyncio\n",
        "from pyodide.ffi import create_proxy\n",
        "\n",
        "# Dictionary to track pending requests\n",
        "pending_requests = {}\n",
        "request_id = 0\n",
        "\n",
        "def handle_worker_message(event):\n",
        "    \"\"\"Handle messages coming back from the worker\"\"\"\n",
        "    data = event.data\n",
        "    msg_type = data.type\n",
        "    msg_id = data.id\n",
        "    \n",
        "    if msg_id in pending_requests:\n",
        "        # Resolve the promise for this request\n",
        "        resolver = pending_requests[msg_id]\n",
        "        resolver(data)\n",
        "        del pending_requests[msg_id]\n",
        "\n",
        "# Create proxy and attach listener\n",
        "message_handler = create_proxy(handle_worker_message)\n",
        "worker.addEventListener(\"message\", message_handler)\n",
        "print(\"Message listener attached!\")\n",
        "\n",
        "async def send_worker_message(msg_type, data):\n",
        "    \"\"\"Send a message to the worker and wait for response\"\"\"\n",
        "    global request_id\n",
        "    request_id += 1\n",
        "    msg_id = request_id\n",
        "    \n",
        "    # Create a future to wait for the response\n",
        "    future = asyncio.get_event_loop().create_future()\n",
        "    pending_requests[msg_id] = lambda result: future.set_result(result)\n",
        "    \n",
        "    # Convert Python dict to JavaScript object using to_js()\n",
        "    from pyodide.ffi import to_js\n",
        "    \n",
        "    message = to_js({\n",
        "        \"type\": msg_type,\n",
        "        \"data\": data,\n",
        "        \"id\": msg_id\n",
        "    }, dict_converter=js.Object.fromEntries)\n",
        "    \n",
        "    # Send message to worker\n",
        "    worker.postMessage(message)\n",
        "    \n",
        "    # Wait for response\n",
        "    response = await future\n",
        "    return response\n",
        "\n",
        "# Now initialize the engine\n",
        "print(\"Initializing WebLLM engine...\")\n",
        "# model=\"Llama-3.2-1B-Instruct-q4f32_1-MLC\"\n",
        "model=\"SmolLM2-360M-Instruct-q4f16_1-MLC\"\n",
        "init_response = await send_worker_message(\"init\", {\n",
        "    \"model\": model\n",
        "})\n",
        "\n",
        "if init_response.type == \"init_complete\":\n",
        "    print(f\"✓ {init_response.data}\")\n",
        "elif init_response.type == \"error\":\n",
        "    print(f\"✗ Error: {init_response.data}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "43bf5a64-1b5b-40b8-8328-962dce46d9fe",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing WebLLM engine...\n"
          ]
        },
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'request_id' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Now initialize the engine\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitializing WebLLM engine...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m init_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m send_worker_message(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSmolLM2-360M-Instruct-q4f16_1-MLC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m })\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m init_response\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_complete\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minit_response\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36msend_worker_message\u001b[0;34m(msg_type, data)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a message to the worker and wait for response\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m request_id\n\u001b[0;32m----> 7\u001b[0m \u001b[43mrequest_id\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      8\u001b[0m msg_id \u001b[38;5;241m=\u001b[39m request_id\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create a future to wait for the response\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'request_id' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "275adcf6-803b-4b19-9758-8bdd5e43e692",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
